{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "225c2be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries required to do Linear Regression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620b99d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mustang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb9900f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows prior to cleaning: 19018575\n",
      "rows after to cleaning: 18147350\n",
      "      user_ID  group_ID                submit_time                 start_time  \\\n",
      "1000      354       357  2011-10-28 13:13:27-06:00  2011-10-28 13:13:45-06:00   \n",
      "1001      354       357  2011-10-28 13:13:34-06:00  2011-10-28 13:13:45-06:00   \n",
      "1002      354       357  2011-10-28 13:13:40-06:00  2011-10-28 13:13:45-06:00   \n",
      "1003      354       357  2011-10-28 13:13:47-06:00  2011-10-28 13:14:16-06:00   \n",
      "1004      427       435  2011-10-28 13:20:06-06:00  2011-10-28 13:20:28-06:00   \n",
      "\n",
      "                       end_time  wallclock_limit job_status  node_count  \\\n",
      "1000  2011-10-28 13:19:36-06:00           7200.0  COMPLETED           8   \n",
      "1001  2011-10-28 13:19:43-06:00           7200.0  COMPLETED           8   \n",
      "1002  2011-10-28 13:19:45-06:00           7200.0  COMPLETED           8   \n",
      "1003  2011-10-28 13:20:31-06:00           7200.0  COMPLETED           8   \n",
      "1004  2011-10-28 13:20:31-06:00           7200.0  COMPLETED           1   \n",
      "\n",
      "      tasks_requested  runtime  \n",
      "1000              192    351.0  \n",
      "1001              192    358.0  \n",
      "1002              192    360.0  \n",
      "1003              192    375.0  \n",
      "1004               24      3.0  \n"
     ]
    }
   ],
   "source": [
    "# Import Training CSV\n",
    "df = pd.read_csv(r\"../Dataset/mustang_release_v1.0beta.csv\")\n",
    "\n",
    "# Data Cleaning Step\n",
    "print(\"rows prior to cleaning: \" + str(df.size))\n",
    "\n",
    "# Drop first 1000 rows\n",
    "df = df.iloc[1000: , :]\n",
    "\n",
    "# Convert wallclock_limit to be in seconds\n",
    "df['wallclock_limit'] = pd.to_timedelta(df['wallclock_limit']).dt.total_seconds()\n",
    "\n",
    "# Add Runtime Attribute\n",
    "df['start_time'] = pd.to_datetime(df['start_time'])\n",
    "df['end_time'] = pd.to_datetime(df['end_time'])\n",
    "df['runtime'] = (df['end_time'] - df['start_time']).dt.total_seconds()\n",
    "\n",
    "# We only care about jobs that are completed\n",
    "df = df[df.job_status == 'COMPLETED']\n",
    "\n",
    "# Filter to only contain rows that have non-zero runtime\n",
    "df = df.dropna(subset=['start_time'])\n",
    "df = df.dropna(subset=['end_time'])\n",
    "df = df[df.runtime != 0]\n",
    "\n",
    "print('rows after to cleaning: ' + str(df.size))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "559e8495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to Attributes(X) and Labels(y).\n",
    "X = df[['user_ID', 'group_ID', 'wallclock_limit', 'node_count', 'tasks_requested']]\n",
    "y = df[['runtime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5872225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into training and testing sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "regressor = LinearRegression()\n",
    "  \n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c591e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a470f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2546.403997021186\n",
      "Mean Squared Error: 41671659.063300684\n",
      "Root Mean Squared Error: 6455.3589414765065\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6a42d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         actual    Predicted\n",
      "2011656     6.0  5892.981941\n",
      "682778     85.0  1608.022655\n",
      "937396    195.0  1389.089923\n",
      "2057438    45.0   330.165995\n",
      "664626     96.0  1607.994425\n"
     ]
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'actual': y_test[\"runtime\"], 'Predicted': y_pred.flatten()})\n",
    "print(df_result.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acac6603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "193f2679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows prior to cleaning: 277607\n",
      "rows after to cleaning: 192408\n",
      "      user_ID  group_ID                submit_time                 start_time  \\\n",
      "1000        1         1  2016-02-05 10:15:47-07:00  2016-02-05 10:15:48-07:00   \n",
      "1001        1         1  2016-02-05 10:15:48-07:00  2016-02-05 10:15:49-07:00   \n",
      "1002        1         1  2016-02-05 10:15:49-07:00  2016-02-05 10:15:50-07:00   \n",
      "1003        1         1  2016-02-05 10:15:50-07:00  2016-02-05 10:15:51-07:00   \n",
      "1004        1         1  2016-02-05 10:15:51-07:00  2016-02-05 10:15:52-07:00   \n",
      "\n",
      "                  dispatch_time                 queue_time  \\\n",
      "1000  2016-02-05 10:15:48-07:00  2016-02-05 10:15:47-07:00   \n",
      "1001  2016-02-05 10:15:49-07:00  2016-02-05 10:15:48-07:00   \n",
      "1002  2016-02-05 10:15:50-07:00  2016-02-05 10:15:49-07:00   \n",
      "1003  2016-02-05 10:15:51-07:00  2016-02-05 10:15:50-07:00   \n",
      "1004  2016-02-05 10:15:52-07:00  2016-02-05 10:15:51-07:00   \n",
      "\n",
      "                       end_time  wallclock_limit job_status  node_count  \\\n",
      "1000  2016-02-05 14:12:32-07:00          20700.0     JOBEND           1   \n",
      "1001  2016-02-05 14:14:23-07:00          20700.0     JOBEND           1   \n",
      "1002  2016-02-05 14:13:48-07:00          20700.0     JOBEND           1   \n",
      "1003  2016-02-05 14:16:17-07:00          20700.0     JOBEND           1   \n",
      "1004  2016-02-05 14:12:32-07:00          20700.0     JOBEND           1   \n",
      "\n",
      "      tasks_requested  runtime  \n",
      "1000                1  14204.0  \n",
      "1001                1  14314.0  \n",
      "1002                1  14278.0  \n",
      "1003                1  14426.0  \n",
      "1004                1  14200.0  \n"
     ]
    }
   ],
   "source": [
    "# Import Training CSV\n",
    "df = pd.read_csv(\"../Dataset/trinity_formatted_release_v1.0beta.csv\")\n",
    "\n",
    "# Data Cleaning Step\n",
    "print(\"rows prior to cleaning: \" + str(df.size))\n",
    "\n",
    "# Drop first 1000 rows\n",
    "df = df.iloc[1000: , :]\n",
    "\n",
    "# Convert wallclock_limit to be in seconds\n",
    "df['wallclock_limit'] = pd.to_timedelta(df['wallclock_limit']).dt.total_seconds()\n",
    "\n",
    "# Add Runtime Attribute\n",
    "df['start_time'] = pd.to_datetime(df['start_time'])\n",
    "df['end_time'] = pd.to_datetime(df['end_time'])\n",
    "df['runtime'] = (df['end_time'] - df['start_time']).dt.total_seconds()\n",
    "\n",
    "# We only care about jobs that are completed\n",
    "df = df[df.job_status == 'JOBEND']\n",
    "\n",
    "# Filter to only contain rows that have non-zero runtime\n",
    "df = df.dropna(subset=['start_time'])\n",
    "df = df.dropna(subset=['end_time'])\n",
    "df = df[df.runtime != 0]\n",
    "\n",
    "print('rows after to cleaning: ' + str(df.size))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d93e4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to Attributes(X) and Labels(y).\n",
    "X = df[['user_ID', 'group_ID', 'wallclock_limit', 'node_count', 'tasks_requested']]\n",
    "y = df[['runtime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "170d8fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into training and testing sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "regressor = LinearRegression()\n",
    "  \n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a58a398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c167708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 4242.142144032407\n",
      "Mean Squared Error: 35291747.63569829\n",
      "Root Mean Squared Error: 5940.685788332715\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c81174f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        actual     Predicted\n",
      "3961   13879.0  10095.374569\n",
      "6077     104.0    -20.908626\n",
      "9830    8137.0   3899.376670\n",
      "15981    427.0   3737.132852\n",
      "5494      25.0   8617.256876\n"
     ]
    }
   ],
   "source": [
    "df_result = pd.DataFrame({'actual': y_test[\"runtime\"], 'Predicted': y_pred.flatten()})\n",
    "print(df_result.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef15809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
