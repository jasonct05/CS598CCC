{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b37df35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, matthews_corrcoef, accuracy_score, precision_score, recall_score, f1_score, fbeta_score, confusion_matrix, make_scorer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from IPython.display import FileLink, FileLinks, clear_output\n",
    "from IPython.display import FileLink, FileLinks\n",
    "from xgboost import XGBRegressor\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bba23d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\rrava\\OneDrive\\Documents\\01 - Fall 2022\\Research Project\\Clean Datasets\\cleaned_RICC_with_waiting_times_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc465434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runtime models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d4ac10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = 3)\n",
    "\n",
    "beta = 0.25\n",
    "fbeta_scorer = make_scorer(fbeta_score, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a7ecfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_time = 15 * 60\n",
    "X = df[['user_id', 'group_id', 'submit_time', 'requested_time', 'requested_CPUs', 'requested_memory']]\n",
    "y = df[['runtime']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af24b86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2c62c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(max_depth=5, max_features='sqrt', min_samples_leaf=50,\n",
      "                      min_samples_split=100, random_state=0)\n",
      "MCC: 0.0\n",
      "F1 score: 0.8483398914692796\n",
      "Precision score: 0.7366234926306386\n",
      "Recall score: 1.0\n",
      "FBeta score: 0.7482153960286391\n"
     ]
    }
   ],
   "source": [
    "# Runtimes - Regression - Random Forest\n",
    "\n",
    "## Hyperparameter tuning with cross-validation\n",
    "\n",
    "cv_clf = RandomForestRegressor()\n",
    "param_search = {'n_estimators': [100, 250], 'max_features': ['sqrt', 'log2'], 'max_depth': [5, 10, 15], 'min_samples_leaf': [50, 100, 250], 'min_samples_split': [100, 200, 500], 'random_state': [0]}\n",
    "gsearch = GridSearchCV(estimator=cv_clf, cv=tscv, param_grid=param_search, scoring='neg_mean_absolute_error')\n",
    "gsearch.fit(X_train, y_train.values.ravel())\n",
    "print(gsearch.best_estimator_)\n",
    "\n",
    "## Test set evaluation\n",
    "\n",
    "y_pred = gsearch.predict(X_test)\n",
    "\n",
    "y_test_binary = y_test['runtime'] > threshold_time\n",
    "y_pred_binary = y_pred > threshold_time\n",
    "\n",
    "print(\"MCC: \" + str(matthews_corrcoef(y_test_binary, y_pred_binary)))\n",
    "print(\"F1 score: \" + str(f1_score(y_test_binary, y_pred_binary)))\n",
    "print(\"Precision score: \" + str(precision_score(y_test_binary, y_pred_binary)))\n",
    "print(\"Recall score: \" + str(recall_score(y_test_binary, y_pred_binary)))\n",
    "print(\"FBeta score: \" + str(fbeta_score(y_test_binary, y_pred_binary, beta=beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89480d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n",
      "MCC: 0.44610386981648803\n",
      "F1 score: 0.8824925091855689\n",
      "Precision score: 0.7982389443476982\n",
      "Recall score: 0.986630691808646\n",
      "FBeta score: 0.80730663833935\n"
     ]
    }
   ],
   "source": [
    "# Runtimes - Regression - Linear Regression\n",
    "\n",
    "## Hyperparameter tuning with cross-validation\n",
    "\n",
    "cv_clf = LinearRegression()\n",
    "param_search = {}\n",
    "gsearch = GridSearchCV(estimator=cv_clf, cv=tscv, param_grid=param_search, scoring='neg_mean_absolute_error')\n",
    "gsearch.fit(X_train, y_train.values.ravel())\n",
    "print(gsearch.best_estimator_)\n",
    "\n",
    "## Test set evaluation\n",
    "\n",
    "y_pred = gsearch.predict(X_test)\n",
    "\n",
    "y_test_binary = y_test['runtime'] > threshold_time\n",
    "y_pred_binary = y_pred > threshold_time\n",
    "\n",
    "print(\"MCC: \" + str(matthews_corrcoef(y_test_binary, y_pred_binary)))\n",
    "print(\"F1 score: \" + str(f1_score(y_test_binary, y_pred_binary)))\n",
    "print(\"Precision score: \" + str(precision_score(y_test_binary, y_pred_binary)))\n",
    "print(\"Recall score: \" + str(recall_score(y_test_binary, y_pred_binary)))\n",
    "print(\"FBeta score: \" + str(fbeta_score(y_test_binary, y_pred_binary, beta=beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bcd018c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(max_features='sqrt', min_samples_leaf=250,\n",
      "                          min_samples_split=100, random_state=0)\n",
      "MCC: 0.3576465566520686\n",
      "F1 score: 0.8702592177297013\n",
      "Precision score: 0.7703355986828277\n",
      "Recall score: 0.9999696841084096\n",
      "FBeta score: 0.7808840117534015\n"
     ]
    }
   ],
   "source": [
    "# Runtimes - Regression - Gradient Boosting\n",
    "\n",
    "## Hyperparameter tuning with cross-validation\n",
    "\n",
    "cv_clf = GradientBoostingRegressor()\n",
    "param_search = {'n_estimators': [100, 250], 'max_features': ['sqrt', 'log2'], 'min_samples_leaf': [50, 100, 250], 'min_samples_split': [100, 200, 500], 'random_state': [0]}\n",
    "gsearch = GridSearchCV(estimator=cv_clf, cv=tscv, param_grid=param_search, scoring='neg_mean_absolute_error')\n",
    "gsearch.fit(X_train, y_train.values.ravel())\n",
    "print(gsearch.best_estimator_)\n",
    "\n",
    "## Test set evaluation\n",
    "\n",
    "y_pred = gsearch.predict(X_test)\n",
    "\n",
    "y_test_binary = y_test['runtime'] > threshold_time\n",
    "y_pred_binary = y_pred > threshold_time\n",
    "\n",
    "print(\"MCC: \" + str(matthews_corrcoef(y_test_binary, y_pred_binary)))\n",
    "print(\"F1 score: \" + str(f1_score(y_test_binary, y_pred_binary)))\n",
    "print(\"Precision score: \" + str(precision_score(y_test_binary, y_pred_binary)))\n",
    "print(\"Recall score: \" + str(recall_score(y_test_binary, y_pred_binary)))\n",
    "print(\"FBeta score: \" + str(fbeta_score(y_test_binary, y_pred_binary, beta=beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8a0e31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ad4e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fc262d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['should_wait_runtime_actual'] = df['runtime'] > threshold_time\n",
    "y = df[['should_wait_runtime_actual']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29425a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af594f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10, min_samples_leaf=250,\n",
      "                       min_samples_split=100, random_state=0)\n",
      "MCC: 0.5333896100793349\n",
      "F1 score: 0.8963528784793866\n",
      "Precision score: 0.8159721358377908\n",
      "Recall score: 0.9943006123810101\n",
      "FBeta score: 0.8246724626020182\n"
     ]
    }
   ],
   "source": [
    "# Runtimes - Classification - Random Forest\n",
    "\n",
    "## Hyperparameter tuning with cross-validation\n",
    "\n",
    "cv_clf = RandomForestClassifier()\n",
    "param_search = {'n_estimators': [100], 'max_features': ['sqrt'], 'max_depth': [10], 'min_samples_leaf': [50, 100, 250], 'min_samples_split': [100, 200, 500], 'random_state': [0]}\n",
    "gsearch = GridSearchCV(estimator=cv_clf, cv=tscv, param_grid=param_search, scoring=fbeta_scorer)\n",
    "gsearch.fit(X_train, y_train.values.ravel())\n",
    "print(gsearch.best_estimator_)\n",
    "\n",
    "## Test set evaluation\n",
    "\n",
    "y_pred = gsearch.predict(X_test)\n",
    "\n",
    "print(\"MCC: \" + str(matthews_corrcoef(y_test, y_pred)))\n",
    "print(\"F1 score: \" + str(f1_score(y_test, y_pred)))\n",
    "print(\"Precision score: \" + str(precision_score(y_test, y_pred)))\n",
    "print(\"Recall score: \" + str(recall_score(y_test, y_pred)))\n",
    "print(\"FBeta score: \" + str(fbeta_score(y_test, y_pred, beta=beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37f2b826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(max_features='sqrt', min_samples_leaf=50,\n",
      "                           min_samples_split=500, random_state=0)\n",
      "MCC: 0.5095188393698783\n",
      "F1 score: 0.8922046037193279\n",
      "Precision score: 0.80732503620787\n",
      "Recall score: 0.9970290426241436\n",
      "FBeta score: 0.8164631457202188\n"
     ]
    }
   ],
   "source": [
    "# Runtimes - Classification - Gradient Boosting\n",
    "\n",
    "## Hyperparameter tuning with cross-validation\n",
    "\n",
    "cv_clf = GradientBoostingClassifier()\n",
    "param_search = {'n_estimators': [100], 'max_features': ['sqrt'], 'min_samples_leaf': [50, 100, 250], 'min_samples_split': [100, 200, 500], 'random_state': [0]}\n",
    "gsearch = GridSearchCV(estimator=cv_clf, cv=tscv, param_grid=param_search, scoring=fbeta_scorer)\n",
    "gsearch.fit(X_train, y_train.values.ravel())\n",
    "print(gsearch.best_estimator_)\n",
    "\n",
    "## Test set evaluation\n",
    "\n",
    "y_pred = gsearch.predict(X_test)\n",
    "\n",
    "print(\"MCC: \" + str(matthews_corrcoef(y_test, y_pred)))\n",
    "print(\"F1 score: \" + str(f1_score(y_test, y_pred)))\n",
    "print(\"Precision score: \" + str(precision_score(y_test, y_pred)))\n",
    "print(\"Recall score: \" + str(recall_score(y_test, y_pred)))\n",
    "print(\"FBeta score: \" + str(fbeta_score(y_test, y_pred, beta=beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97912ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, max_iter=1000, random_state=0)\n",
      "MCC: 0.3517939164684428\n",
      "F1 score: 0.8498511517673922\n",
      "Precision score: 0.8119960234176516\n",
      "Recall score: 0.8914084763232887\n",
      "FBeta score: 0.816273608784117\n"
     ]
    }
   ],
   "source": [
    "# Runtimes - Classification - Logistic Regression\n",
    "\n",
    "## Hyperparameter tuning with cross-validation\n",
    "\n",
    "cv_clf = LogisticRegression()\n",
    "param_search = {'max_iter': [1000, 10000], 'C': [0.1, 0.01, 0.001, 0.0001], 'random_state': [0]}\n",
    "gsearch = GridSearchCV(estimator=cv_clf, cv=tscv, param_grid=param_search, scoring=fbeta_scorer)\n",
    "gsearch.fit(X_train, y_train.values.ravel())\n",
    "print(gsearch.best_estimator_)\n",
    "\n",
    "## Test set evaluation\n",
    "\n",
    "y_pred = gsearch.predict(X_test)\n",
    "\n",
    "print(\"MCC: \" + str(matthews_corrcoef(y_test, y_pred)))\n",
    "print(\"F1 score: \" + str(f1_score(y_test, y_pred)))\n",
    "print(\"Precision score: \" + str(precision_score(y_test, y_pred)))\n",
    "print(\"Recall score: \" + str(recall_score(y_test, y_pred)))\n",
    "print(\"FBeta score: \" + str(fbeta_score(y_test, y_pred, beta=beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ae0aaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=50)\n",
      "MCC: 0.02815257410853256\n",
      "F1 score: 0.848480950788465\n",
      "Precision score: 0.7368856121537086\n",
      "Recall score: 0.9999090523252289\n",
      "FBeta score: 0.7484669210007128\n"
     ]
    }
   ],
   "source": [
    "# Runtimes - Classification - Nearest Neighbors\n",
    "\n",
    "## Hyperparameter tuning with cross-validation\n",
    "\n",
    "cv_clf = KNeighborsClassifier()\n",
    "param_search = {'n_neighbors': [5, 10, 15, 25, 50]}\n",
    "gsearch = GridSearchCV(estimator=cv_clf, cv=tscv, param_grid=param_search, scoring=fbeta_scorer)\n",
    "gsearch.fit(X_train, y_train.values.ravel())\n",
    "print(gsearch.best_estimator_)\n",
    "\n",
    "## Test set evaluation\n",
    "\n",
    "y_pred = gsearch.predict(X_test)\n",
    "\n",
    "print(\"MCC: \" + str(matthews_corrcoef(y_test, y_pred)))\n",
    "print(\"F1 score: \" + str(f1_score(y_test, y_pred)))\n",
    "print(\"Precision score: \" + str(precision_score(y_test, y_pred)))\n",
    "print(\"Recall score: \" + str(recall_score(y_test, y_pred)))\n",
    "print(\"FBeta score: \" + str(fbeta_score(y_test, y_pred, beta=beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "321802ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(var_smoothing=1e-11)\n",
      "MCC: 0.20485912106895296\n",
      "F1 score: 0.8287052714753357\n",
      "Precision score: 0.7751148181386264\n",
      "Recall score: 0.8902564724428546\n",
      "FBeta score: 0.7810570716031302\n"
     ]
    }
   ],
   "source": [
    "# Runtimes - Classification - Naive Bayes\n",
    "\n",
    "## Hyperparameter tuning with cross-validation\n",
    "\n",
    "cv_clf = GaussianNB()\n",
    "param_search = {'var_smoothing': [1e-11, 1e-10, 1e-9]}\n",
    "gsearch = GridSearchCV(estimator=cv_clf, cv=tscv, param_grid=param_search, scoring=fbeta_scorer)\n",
    "gsearch.fit(X_train, y_train.values.ravel())\n",
    "print(gsearch.best_estimator_)\n",
    "\n",
    "## Test set evaluation\n",
    "\n",
    "y_pred = gsearch.predict(X_test)\n",
    "\n",
    "print(\"MCC: \" + str(matthews_corrcoef(y_test, y_pred)))\n",
    "print(\"F1 score: \" + str(f1_score(y_test, y_pred)))\n",
    "print(\"Precision score: \" + str(precision_score(y_test, y_pred)))\n",
    "print(\"Recall score: \" + str(recall_score(y_test, y_pred)))\n",
    "print(\"FBeta score: \" + str(fbeta_score(y_test, y_pred, beta=beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41480588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a2fd49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Waiting Time Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89512c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_remaining_runtime'] = df['running_job_requested_wallclock_limit'] - df['elapsed_runtime_total']\n",
    "df['average_remaining_runtime'] = df['running_job_mean_wallclock_limit'] - df['elapsed_runtime_mean']\n",
    "\n",
    "X = df[['total_remaining_runtime', 'average_remaining_runtime', 'user_id', 'queue_number', 'submit_time', 'requested_time', 'requested_CPUs', 'num_running_jobs', 'num_waiting_jobs', 'running_job_mean_CPU_time', 'running_job_requested_wallclock_limit', 'running_job_mean_wallclock_limit', 'waiting_job_requested_CPU_time', 'waiting_job_mean_CPU_time', 'waiting_job_requested_wallclock_limit', 'waiting_job_mean_wallclock_limit', 'elapsed_runtime_total', 'elapsed_runtime_mean', 'elapsed_waiting_time_total', 'elapsed_waiting_time_mean']]\n",
    "\n",
    "y = df[['wait_time']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, shuffle = False)\n",
    "\n",
    "waiting_time_threshold = 6 * 60 * 60\n",
    "beta = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6b9a16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(max_depth=10, max_features='sqrt', min_samples_leaf=100,\n",
      "                      min_samples_split=100, random_state=0)\n",
      "MCC: 0.13075374854708938\n",
      "F1 score: 0.26252983293556087\n",
      "Precision score: 0.1510989010989011\n",
      "Recall score: 1.0\n",
      "FBeta score: 0.1590406531723082\n"
     ]
    }
   ],
   "source": [
    "# Waiting Times - Regression - Random Forest\n",
    "\n",
    "## Hyperparameter tuning with cross-validation\n",
    "\n",
    "cv_clf = RandomForestRegressor()\n",
    "param_search = {'n_estimators': [100], 'max_features': ['sqrt'], 'max_depth': [10], 'min_samples_leaf': [50, 100, 250], 'min_samples_split': [100, 200, 500], 'random_state': [0]}\n",
    "gsearch = GridSearchCV(estimator=cv_clf, cv=tscv, param_grid=param_search, scoring='neg_mean_absolute_error')\n",
    "gsearch.fit(X_train, y_train.values.ravel())\n",
    "print(gsearch.best_estimator_)\n",
    "\n",
    "## Test set evaluation\n",
    "\n",
    "y_pred = gsearch.predict(X_test)\n",
    "\n",
    "y_test_binary = y_test['wait_time'] > threshold_time\n",
    "y_pred_binary = y_pred > threshold_time\n",
    "\n",
    "print(\"MCC: \" + str(matthews_corrcoef(y_test_binary, y_pred_binary)))\n",
    "print(\"F1 score: \" + str(f1_score(y_test_binary, y_pred_binary)))\n",
    "print(\"Precision score: \" + str(precision_score(y_test_binary, y_pred_binary)))\n",
    "print(\"Recall score: \" + str(recall_score(y_test_binary, y_pred_binary)))\n",
    "print(\"FBeta score: \" + str(fbeta_score(y_test_binary, y_pred_binary, beta=beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "560d5bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n",
      "MCC: 0.37931654709702844\n",
      "F1 score: 0.4675635617375442\n",
      "Precision score: 0.35857305237387427\n",
      "Recall score: 0.6717444717444717\n",
      "FBeta score: 0.36868379720460925\n"
     ]
    }
   ],
   "source": [
    "# Waiting Times - Regression - Linear Regression\n",
    "\n",
    "## Hyperparameter tuning with cross-validation\n",
    "\n",
    "cv_clf = LinearRegression()\n",
    "param_search = {}\n",
    "gsearch = GridSearchCV(estimator=cv_clf, cv=tscv, param_grid=param_search, scoring='neg_mean_absolute_error')\n",
    "gsearch.fit(X_train, y_train.values.ravel())\n",
    "print(gsearch.best_estimator_)\n",
    "\n",
    "## Test set evaluation\n",
    "\n",
    "y_pred = gsearch.predict(X_test)\n",
    "\n",
    "y_test_binary = y_test['wait_time'] > threshold_time\n",
    "y_pred_binary = y_pred > threshold_time\n",
    "\n",
    "print(\"MCC: \" + str(matthews_corrcoef(y_test_binary, y_pred_binary)))\n",
    "print(\"F1 score: \" + str(f1_score(y_test_binary, y_pred_binary)))\n",
    "print(\"Precision score: \" + str(precision_score(y_test_binary, y_pred_binary)))\n",
    "print(\"Recall score: \" + str(recall_score(y_test_binary, y_pred_binary)))\n",
    "print(\"FBeta score: \" + str(fbeta_score(y_test_binary, y_pred_binary, beta=beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cd6212c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(max_features='sqrt', min_samples_leaf=100,\n",
      "                          min_samples_split=500, random_state=0)\n",
      "MCC: 0.17649811910389684\n",
      "F1 score: 0.3054508275289156\n",
      "Precision score: 0.18973524391696106\n",
      "Recall score: 0.782964782964783\n",
      "FBeta score: 0.19858599731666965\n"
     ]
    }
   ],
   "source": [
    "# Waiting Times - Regression - Gradient Boosting\n",
    "\n",
    "## Hyperparameter tuning with cross-validation\n",
    "\n",
    "cv_clf = GradientBoostingRegressor()\n",
    "param_search = {'n_estimators': [100], 'max_features': ['sqrt'], 'min_samples_leaf': [50, 100, 250], 'min_samples_split': [100, 200, 500], 'random_state': [0]}\n",
    "gsearch = GridSearchCV(estimator=cv_clf, cv=tscv, param_grid=param_search, scoring='neg_mean_absolute_error')\n",
    "gsearch.fit(X_train, y_train.values.ravel())\n",
    "print(gsearch.best_estimator_)\n",
    "\n",
    "## Test set evaluation\n",
    "\n",
    "y_pred = gsearch.predict(X_test)\n",
    "\n",
    "y_test_binary = y_test['wait_time'] > threshold_time\n",
    "y_pred_binary = y_pred > threshold_time\n",
    "\n",
    "print(\"MCC: \" + str(matthews_corrcoef(y_test_binary, y_pred_binary)))\n",
    "print(\"F1 score: \" + str(f1_score(y_test_binary, y_pred_binary)))\n",
    "print(\"Precision score: \" + str(precision_score(y_test_binary, y_pred_binary)))\n",
    "print(\"Recall score: \" + str(recall_score(y_test_binary, y_pred_binary)))\n",
    "print(\"FBeta score: \" + str(fbeta_score(y_test_binary, y_pred_binary, beta=beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab8bcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0173acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waiting time classification\n",
    "df['should_wait_waiting_time_actual'] = df['wait_time'] < waiting_time_threshold\n",
    "y = df[['should_wait_waiting_time_actual']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bce35d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10, min_samples_leaf=100,\n",
      "                       min_samples_split=100, random_state=0)\n",
      "MCC: 0.40950711724441824\n",
      "F1 score: 0.9842452215837036\n",
      "Precision score: 0.9698518485162336\n",
      "Recall score: 0.9990722486373652\n",
      "FBeta score: 0.9715232991791589\n"
     ]
    }
   ],
   "source": [
    "# Waiting Times - Classification - Random Forest\n",
    "\n",
    "## Hyperparameter tuning with cross-validation\n",
    "\n",
    "cv_clf = RandomForestClassifier()\n",
    "param_search = {'n_estimators': [100], 'max_features': ['sqrt'], 'max_depth': [10], 'min_samples_leaf': [50, 100, 250], 'min_samples_split': [100, 200, 500], 'random_state': [0]}\n",
    "gsearch = GridSearchCV(estimator=cv_clf, cv=tscv, param_grid=param_search, scoring=fbeta_scorer)\n",
    "gsearch.fit(X_train, y_train.values.ravel())\n",
    "print(gsearch.best_estimator_)\n",
    "\n",
    "## Test set evaluation\n",
    "\n",
    "y_pred = gsearch.predict(X_test)\n",
    "\n",
    "print(\"MCC: \" + str(matthews_corrcoef(y_test, y_pred)))\n",
    "print(\"F1 score: \" + str(f1_score(y_test, y_pred)))\n",
    "print(\"Precision score: \" + str(precision_score(y_test, y_pred)))\n",
    "print(\"Recall score: \" + str(recall_score(y_test, y_pred)))\n",
    "print(\"FBeta score: \" + str(fbeta_score(y_test, y_pred, beta=beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69a65f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(max_features='sqrt', min_samples_leaf=100,\n",
      "                           min_samples_split=500, random_state=0)\n",
      "MCC: 0.41650887376593954\n",
      "F1 score: 0.9842790665767239\n",
      "Precision score: 0.9705961937404167\n",
      "Recall score: 0.9983532413313232\n",
      "FBeta score: 0.9721861660220839\n"
     ]
    }
   ],
   "source": [
    "# Waiting Times - Classification - Gradient Boosting\n",
    "\n",
    "## Hyperparameter tuning with cross-validation\n",
    "\n",
    "cv_clf = GradientBoostingClassifier()\n",
    "param_search = {'n_estimators': [100], 'max_features': ['sqrt'], 'min_samples_leaf': [50, 100, 250], 'min_samples_split': [100, 200, 500], 'random_state': [0]}\n",
    "gsearch = GridSearchCV(estimator=cv_clf, cv=tscv, param_grid=param_search, scoring=fbeta_scorer)\n",
    "gsearch.fit(X_train, y_train.values.ravel())\n",
    "print(gsearch.best_estimator_)\n",
    "\n",
    "## Test set evaluation\n",
    "\n",
    "y_pred = gsearch.predict(X_test)\n",
    "\n",
    "print(\"MCC: \" + str(matthews_corrcoef(y_test, y_pred)))\n",
    "print(\"F1 score: \" + str(f1_score(y_test, y_pred)))\n",
    "print(\"Precision score: \" + str(precision_score(y_test, y_pred)))\n",
    "print(\"Recall score: \" + str(recall_score(y_test, y_pred)))\n",
    "print(\"FBeta score: \" + str(fbeta_score(y_test, y_pred, beta=beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6509979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.0001, max_iter=1000, random_state=0)\n",
      "MCC: 0.0\n",
      "F1 score: 0.9810569429432846\n",
      "Precision score: 0.9628182224207236\n",
      "Recall score: 1.0\n",
      "FBeta score: 0.9649286790987303\n"
     ]
    }
   ],
   "source": [
    "# Waiting Times - Classification - Logistic Regression\n",
    "\n",
    "## Hyperparameter tuning with cross-validation\n",
    "\n",
    "cv_clf = LogisticRegression()\n",
    "param_search = {'max_iter': [1000, 10000], 'C': [0.1, 0.01, 0.001, 0.0001], 'random_state': [0]}\n",
    "gsearch = GridSearchCV(estimator=cv_clf, cv=tscv, param_grid=param_search, scoring=fbeta_scorer)\n",
    "gsearch.fit(X_train, y_train.values.ravel())\n",
    "print(gsearch.best_estimator_)\n",
    "\n",
    "## Test set evaluation\n",
    "\n",
    "y_pred = gsearch.predict(X_test)\n",
    "\n",
    "print(\"MCC: \" + str(matthews_corrcoef(y_test, y_pred)))\n",
    "print(\"F1 score: \" + str(f1_score(y_test, y_pred)))\n",
    "print(\"Precision score: \" + str(precision_score(y_test, y_pred)))\n",
    "print(\"Recall score: \" + str(recall_score(y_test, y_pred)))\n",
    "print(\"FBeta score: \" + str(fbeta_score(y_test, y_pred, beta=beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c17ec8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=50)\n",
      "MCC: -0.012196409060691105\n",
      "F1 score: 0.9375118934348239\n",
      "Precision score: 0.9621139997558892\n",
      "Recall score: 0.914136611388148\n",
      "FBeta score: 0.9591528226123927\n"
     ]
    }
   ],
   "source": [
    "# Waiting Times - Classification - Nearest Neighbors\n",
    "\n",
    "## Hyperparameter tuning with cross-validation\n",
    "\n",
    "cv_clf = KNeighborsClassifier()\n",
    "param_search = {'n_neighbors': [5, 10, 15, 25, 50]}\n",
    "gsearch = GridSearchCV(estimator=cv_clf, cv=tscv, param_grid=param_search, scoring=fbeta_scorer)\n",
    "gsearch.fit(X_train, y_train.values.ravel())\n",
    "print(gsearch.best_estimator_)\n",
    "\n",
    "## Test set evaluation\n",
    "\n",
    "y_pred = gsearch.predict(X_test)\n",
    "\n",
    "print(\"MCC: \" + str(matthews_corrcoef(y_test, y_pred)))\n",
    "print(\"F1 score: \" + str(f1_score(y_test, y_pred)))\n",
    "print(\"Precision score: \" + str(precision_score(y_test, y_pred)))\n",
    "print(\"Recall score: \" + str(recall_score(y_test, y_pred)))\n",
    "print(\"FBeta score: \" + str(fbeta_score(y_test, y_pred, beta=beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc5f43e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(var_smoothing=1e-11)\n",
      "MCC: -0.00624689959685952\n",
      "F1 score: 0.9800236891257801\n",
      "Precision score: 0.9627648862136096\n",
      "Recall score: 0.9979125594340716\n",
      "FBeta score: 0.9647637174713343\n"
     ]
    }
   ],
   "source": [
    "# Waiting Times - Classification - Naive Bayes\n",
    "\n",
    "## Hyperparameter tuning with cross-validation\n",
    "\n",
    "cv_clf = GaussianNB()\n",
    "param_search = {'var_smoothing': [1e-11, 1e-10, 1e-9]}\n",
    "gsearch = GridSearchCV(estimator=cv_clf, cv=tscv, param_grid=param_search, scoring=fbeta_scorer)\n",
    "gsearch.fit(X_train, y_train.values.ravel())\n",
    "print(gsearch.best_estimator_)\n",
    "\n",
    "## Test set evaluation\n",
    "\n",
    "y_pred = gsearch.predict(X_test)\n",
    "\n",
    "print(\"MCC: \" + str(matthews_corrcoef(y_test, y_pred)))\n",
    "print(\"F1 score: \" + str(f1_score(y_test, y_pred)))\n",
    "print(\"Precision score: \" + str(precision_score(y_test, y_pred)))\n",
    "print(\"Recall score: \" + str(recall_score(y_test, y_pred)))\n",
    "print(\"FBeta score: \" + str(fbeta_score(y_test, y_pred, beta=beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c73e591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
